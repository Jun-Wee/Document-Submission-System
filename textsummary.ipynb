{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e3d4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from transformers) (1.22.3)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp38-cp38-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 3.0 MB/s eta 0:00:00\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp38-cp38-win_amd64.whl (155 kB)\n",
      "     -------------------------------------- 155.4/155.4 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.7.25-cp38-cp38-win_amd64.whl (262 kB)\n",
      "     -------------------------------------- 262.8/262.8 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.4/78.4 kB ? eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Installing collected packages: tokenizers, tqdm, regex, pyyaml, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.7.1 huggingface-hub-0.8.1 pyyaml-6.0 regex-2022.7.25 tokenizers-0.12.1 tqdm-4.64.0 transformers-4.20.1\n"
     ]
    }
   ],
   "source": [
    "#text summary using hugging transformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a38ae568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "294860bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 851M/851M [05:23<00:00, 2.76MB/s]    \n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "Downloading: 100%|██████████| 773k/773k [00:03<00:00, 233kB/s]  \n",
      "Downloading: 100%|██████████| 1.32M/1.32M [00:04<00:00, 324kB/s] \n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# use bart model in pytorch\n",
    "#t5 in tensorflow will need to be checked against this \n",
    "#summarizer = pipeline('summarization')\n",
    "summarizer = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d48cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This would have to be the result from pdfparser passed onto this variable\n",
    "article = \"\"\"Based on the information presented in the section of justification, most evidence gravitate towards a number \n",
    "of ethical principles and codes of conduct that also consider the realm of professionalism. Firstly, according \n",
    "to Kant’s categorical imperative, the act of whistleblowing is considered ethically wrong. It steers away from \n",
    "the initial promise of remaining loyal to their organization, which also ties with professionalism; Kant’s theory \n",
    "states that there will be no exception regardless of status or change in circumstances which is difficult to \n",
    "achieve in a modern world where rising technology creates many positive or negative unknowns in the future.\n",
    "Secondly, in contrast to the principle above, utilitarianism would consider whistleblowing as a justifiable action \n",
    "as it serves a greater good. The intent of whistleblowing is to put the happiness of a greater volume of \n",
    "individuals, where in this instance the public population would exceed the number of individuals \n",
    "“compromised” in the organization. According to (Kleinig, 2022), it would still be considered a justifiable action, \n",
    "even if the whistleblower was initially motivated by a negative factor, such as revenge. Thirdly, the risk \n",
    "aversion philosophy shows that there is no definite stance if whistleblowing is ethical or not. It depends on \n",
    "how severe the consequence would be if the whistle was or was not blown. Furthermore, the question of \n",
    "which entity would be considered worthy of less harm makes it difficult to give an answer based on this \n",
    "principle.\n",
    "As most whistleblowing instances discussed in the justification section, it is appropriate to consider a code of \n",
    "conduct within a professional context. If the code of conduct within the organization suggests that their \n",
    "primary concern is the publics’ interest, then the whistleblower has the ability to commit the act without \n",
    "maintaining professionalism, which would be the socially ethical. Yet again, the argument of justification for \n",
    "whistleblowing also depends on the contents of the code of conduct and the order in which the values are \n",
    "prioritized in the event of a conflict, so it would be difficult to make a definite decision based on this factor \n",
    "alone. Furthermore, the introduction to whistleblower protection laws suggests that it can be considered \n",
    "justifiable to a degree.\"\"\"\n",
    "\n",
    "summ = summarizer(article,max_length=300, min_length = 100, do_sample = False) #using a greedy decoder for deciding what word to return next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "398a3064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the act of whistleblowing is considered ethically wrong . it steers away from the initial promise of remaining loyal to their organization, which also ties with professionalism . the introduction to whistleblower protection laws suggests that it can be considered justifiable to a degree . if the whistle was or was not blown, it would be ethical to commit the act without maintaining professionalism, which would be the socially ethical . however, there is no definite stance if whistleblawing is ethical or not .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#heres how the summarized info can be extracted \n",
    "summ[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee7736ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
